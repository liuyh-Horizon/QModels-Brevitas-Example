{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f0f9143-bc4e-4884-87b6-16fa560bff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import brevitas.nn as qnn\n",
    "from brevitas.inject.enum import QuantType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bda99bce-4f96-43c8-bec0-1801261aadad",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = 10\n",
    "in_batch = 3\n",
    "out_features = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cef87b7f-8d81-46c2-8660-0a1c7dff298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_torch = nn.Linear(in_features=in_features, out_features=out_features, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c530e6a4-33a4-48ca-8c97-38596d14cc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],\n",
      "        [10., 11., 12., 13., 14., 15., 16., 17., 18., 19.],\n",
      "        [20., 21., 22., 23., 24., 25., 26., 27., 28., 29.]]) \n",
      "\n",
      "Input Shape: \n",
      " torch.Size([3, 10])\n"
     ]
    }
   ],
   "source": [
    "input = torch.arange(0, (in_features*in_batch), dtype=torch.float32).reshape(in_batch, in_features)\n",
    "print(\"Input: \\n\", input, \"\\n\")\n",
    "print(\"Input Shape: \\n\", input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9165811-7e82-461a-b9df-55684ef93084",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: \n",
      " tensor([[  6.0250,  -5.1828,  -3.8589,   3.2993],\n",
      "        [ 11.9521,  -8.6875, -11.3158,   5.9960],\n",
      "        [ 17.8791, -12.1922, -18.7727,   8.6927]], grad_fn=<MmBackward0>) \n",
      "\n",
      "Output Shape: \n",
      " torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "output = fc_torch(input)\n",
    "print(\"Output: \\n\", output, \"\\n\")\n",
    "print(\"Output Shape: \\n\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84c03c02-5139-4087-83c0-4f7dfaf7c397",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_bit_width = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa039d42-49b3-40fc-b0c7-75590c751e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_brevtias = qnn.QuantLinear(\n",
    "                         in_features, \n",
    "                         out_features, \n",
    "                         weight_bit_width=weight_bit_width,\n",
    "                         weight_quant_type=QuantType.INT,\n",
    "                         bias=False\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b21cf2ee-5980-481a-a023-d3025d4bb89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],\n",
      "        [10., 11., 12., 13., 14., 15., 16., 17., 18., 19.],\n",
      "        [20., 21., 22., 23., 24., 25., 26., 27., 28., 29.]]) \n",
      "\n",
      "Input Shape: \n",
      " torch.Size([3, 10])\n"
     ]
    }
   ],
   "source": [
    "input = torch.arange(0, (in_features*in_batch), dtype=torch.float32).reshape(in_batch, in_features)\n",
    "print(\"Input: \\n\", input, \"\\n\")\n",
    "print(\"Input Shape: \\n\", input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a86c6cc2-cfbf-4c3c-a4e4-9b64bd137fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: \n",
      " tensor([[ 1.3777e+00,  6.3361e+00, -1.0303e+00, -2.4129e-03],\n",
      "        [ 5.8656e+00,  1.7797e+01, -3.3949e+00, -2.9195e-01],\n",
      "        [ 1.0353e+01,  2.9258e+01, -5.7594e+00, -5.8149e-01]],\n",
      "       grad_fn=<MmBackward0>) \n",
      "\n",
      "Output Shape: \n",
      " torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "output = fc_brevtias(input)\n",
    "print(\"Output: \\n\", output, \"\\n\")\n",
    "print(\"Output Shape: \\n\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "199d94a0-e362-451b-a0f2-24d306b84550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1873,  0.0713,  0.1197, -0.2085,  0.2534, -0.2766,  0.1688,  0.0643,\n",
       "         -0.0056,  0.0702],\n",
       "        [ 0.1553, -0.1768,  0.1419,  0.2165,  0.2388, -0.1434,  0.1745,  0.2389,\n",
       "          0.0745,  0.2245],\n",
       "        [ 0.1911,  0.1431, -0.1837, -0.0698, -0.2489, -0.1370, -0.3064,  0.1281,\n",
       "          0.2084,  0.0405],\n",
       "        [-0.0802,  0.1470, -0.0577, -0.0128, -0.0954,  0.1145, -0.1578,  0.2424,\n",
       "         -0.2232,  0.0974]], requires_grad=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_brevtias.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4f4595b-9100-45e3-bbd8-206b1b738868",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = nn.BatchNorm1d(out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06c14502-f1f2-4891-a454-17badfbc4a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: \n",
      " tensor([[-1.2247e+00, -1.2247e+00,  1.2247e+00,  1.2246e+00],\n",
      "        [ 9.3746e-08,  1.6303e-08,  1.0984e-07,  6.7152e-07],\n",
      "        [ 1.2247e+00,  1.2247e+00, -1.2247e+00, -1.2246e+00]],\n",
      "       grad_fn=<NativeBatchNormBackward0>) \n",
      "\n",
      "Output Shape: \n",
      " torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "output = bn(output)\n",
    "print(\"Output: \\n\", output, \"\\n\")\n",
    "print(\"Output Shape: \\n\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ab29213-9d81-466f-9f98-3c77e5b43e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "quan_bit_width = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f6a9ffe-33ef-452e-80e6-a61aa5c9ad79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: \n",
      " tensor([[-1.3513e-01, -1.3513e-01,  1.0896e+00,  1.0895e+00],\n",
      "        [ 4.6873e-08,  8.1513e-09,  5.4920e-08,  3.3576e-07],\n",
      "        [ 1.0896e+00,  1.0896e+00, -1.3513e-01, -1.3515e-01]],\n",
      "       grad_fn=<GeluBackward0>) \n",
      "\n",
      "Output Shape: \n",
      " torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "gelu = nn.GELU()\n",
    "output = gelu(output)\n",
    "print(\"Output: \\n\", output, \"\\n\")\n",
    "print(\"Output Shape: \\n\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9829d633-9f80-4d1f-825b-38e8e950a820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: \n",
      " QuantTensor(value=tensor([[-0., -0., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 1., -0., -0.]], grad_fn=<MulBackward0>), scale=tensor(1.), zero_point=tensor(0.), bit_width=tensor(8.), signed_t=tensor(True), training_t=tensor(True)) \n",
      "\n",
      "Output Shape: \n",
      " torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "quant_gelu = qnn.QuantIdentity(\n",
    "                         quant_type='int',\n",
    "                         scaling_impl_type='const',\n",
    "                         bit_width=quan_bit_width,\n",
    "                         min_val=-128.0,\n",
    "                         max_val=127.0, \n",
    "                         return_quant_tensor=True\n",
    "                     )\n",
    "output = quant_gelu(output)\n",
    "print(\"Output: \\n\", output, \"\\n\")\n",
    "print(\"Output Shape: \\n\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cc93088-85e2-489b-b626-bc726062a372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: \n",
      " QuantTensor(value=tensor([[-0.8410, -0.8410,  0.8345,  0.8345],\n",
      "        [ 0.0000,  0.0000,  0.0000, -0.0000],\n",
      "        [ 0.8345,  0.8345, -0.8410, -0.8410]], grad_fn=<MulBackward0>), scale=tensor(0.0066, grad_fn=<DivBackward0>), zero_point=tensor(0.), bit_width=tensor(8.), signed_t=tensor(True), training_t=tensor(True)) \n",
      "\n",
      "Output Shape: \n",
      " torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "output = quant_relu(output)\n",
    "print(\"Output: \\n\", output, \"\\n\")\n",
    "print(\"Output Shape: \\n\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6d752f8-aa1f-456e-bb63-57950c035165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: \n",
      " tensor([[-128., -128.,  127.,  127.],\n",
      "        [   0.,    0.,    0.,    0.],\n",
      "        [ 127.,  127., -128., -128.]], grad_fn=<AddBackward0>) \n",
      "\n",
      "Output Shape: \n",
      " torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "output = output._pre_round_int_value\n",
    "print(\"Output: \\n\", output, \"\\n\")\n",
    "print(\"Output Shape: \\n\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ab1f25-774a-4c01-9411-3ff56c9b7d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size=(3,3)   \n",
    "\n",
    "in_channels1=1\n",
    "out_channels1=64 \n",
    "\n",
    "in_channels2=64\n",
    "out_channels2=64\n",
    "\n",
    "input_size = 7*7*64 \n",
    "\n",
    "weight_bit_width = 1\n",
    "act_bit_width = 1\n",
    "\n",
    "hidden1 = 64   \n",
    "num_classes = 10  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195b96d6-4a7f-4a2a-851f-eee5e409b975",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCV_W8A8(Module):\n",
    "    def __init__(self):\n",
    "        super(TCV_W8A8, self).__init__()\n",
    "        \n",
    "        self.input = qnn.QuantIdentity(\n",
    "                         quant_type='int',\n",
    "                         scaling_impl_type='const',\n",
    "                         bit_width=quan_bit_width,\n",
    "                         min_val=-128.0,\n",
    "                         max_val=127.0, \n",
    "                         return_quant_tensor=True\n",
    "                     )\n",
    "        \n",
    "        self.conv1 = qnn.QuantConv2d( \n",
    "                         in_channels=in_channels1,\n",
    "                         out_channels=out_channels1,\n",
    "                         kernel_size=kernel_size, \n",
    "                         stride=1, \n",
    "                         padding=1,\n",
    "                         weight_bit_width=weight_bit_width,\n",
    "                         weight_quant_type=QuantType.BINARY,\n",
    "                         bias=False\n",
    "                     )\n",
    "        \n",
    "        self.bn1   = nn.BatchNorm2d(out_channels1)\n",
    "        self.relu1 = qnn.QuantReLU(\n",
    "                         bit_width=act_bit_width, \n",
    "                         return_quant_tensor=True\n",
    "                     )\n",
    "        \n",
    "        self.pool1 = qnn.QuantMaxPool2d(2, return_quant_tensor=True)\n",
    "        \n",
    "        self.conv2 = qnn.QuantConv2d( \n",
    "                         in_channels=in_channels2,\n",
    "                         out_channels=out_channels2,\n",
    "                         kernel_size=kernel_size, \n",
    "                         stride=1, \n",
    "                         padding=1,\n",
    "                         weight_bit_width=weight_bit_width,\n",
    "                         weight_quant_type=QuantType.BINARY,\n",
    "                         bias=False\n",
    "                     )\n",
    "        \n",
    "        self.bn2   = nn.BatchNorm2d(out_channels2)\n",
    "        self.relu2 = qnn.QuantReLU(\n",
    "                         bit_width=act_bit_width, \n",
    "                         return_quant_tensor=True\n",
    "                     )\n",
    "        \n",
    "        self.pool2 = qnn.QuantMaxPool2d(2, return_quant_tensor=True)\n",
    "        \n",
    "        self.fc1   = qnn.QuantLinear(\n",
    "                         input_size, \n",
    "                         hidden1, \n",
    "                         weight_bit_width=weight_bit_width,\n",
    "                         weight_quant_type=QuantType.BINARY,\n",
    "                         bias=False\n",
    "                     )\n",
    "        \n",
    "        self.bn3   = nn.BatchNorm1d(hidden1)\n",
    "        self.relu3 = qnn.QuantReLU(\n",
    "                         bit_width=act_bit_width, \n",
    "                         return_quant_tensor=True\n",
    "                     )\n",
    "        \n",
    "        self.out   = qnn.QuantLinear(\n",
    "                         hidden1, \n",
    "                         num_classes, \n",
    "                         weight_bit_width=weight_bit_width,\n",
    "                         weight_quant_type=QuantType.BINARY,\n",
    "                         bias=False\n",
    "                     )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.input(x) # MNIST INPUT 28x28 channel 1 => 28x28x1\n",
    "        out = self.pool1(self.relu1(self.bn1(self.conv1(out))))\n",
    "                            # Conv OUTPUT 28X28 channel 64 => 28x28x64\n",
    "                            # MaxPool OUTPUT 14x14 channel 64 => 14x14x64\n",
    "        out = self.pool2(self.relu2(self.bn2(self.conv2(out))))\n",
    "                            # Conv OUTPUT 14X14 channel 64 => 14x14x64\n",
    "                            # MaxPool OUTPUT 7x7 channel 64 => 7x7x64\n",
    "        out = out.reshape(out.shape[0], -1) # FC INPUT 7X7X64\n",
    "        out = self.relu3(self.bn3(self.fc1(out))) # FC OUTPUT 64\n",
    "        out = self.out(out) # OUTPUT 10\n",
    "        return out\n",
    "   \n",
    "model = TCV_W1A1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19929d03-4774-4f1d-aa57-f6b90eb9c572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
