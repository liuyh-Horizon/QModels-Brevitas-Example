{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd6a89c7-5184-4ec6-82c0-a44407ea1628",
   "metadata": {},
   "source": [
    "# __Quick Tutorial of Brevitas for Hardware-Oriented QNN Traning__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aba60ba-01dd-4856-8e23-64a9c8cdae41",
   "metadata": {},
   "source": [
    "##### *Author: Yuhao Liu, TU Dresden & ScaDS.AI, Email: yuhao.liu1@tu-dresden.de*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb1f9a2-df3b-4f56-9ae8-b4468f52ce1e",
   "metadata": {},
   "source": [
    "## __Section I: Library Import for Tutorial__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4bfaac-f6b2-4cd3-bde2-8d6070ee01f8",
   "metadata": {},
   "source": [
    "#### __1.1 Improt PyTorch Library__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f0f9143-bc4e-4884-87b6-16fa560bff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8386fb-8b49-4a2f-bc89-61bcc8b58768",
   "metadata": {},
   "source": [
    "#### __1.2 Import Basic Brevitas 0.11 Library__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c74a9215-568d-4904-9b31-0dfccfab48de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import brevitas.nn as qnn # Import QNN layers in Brevitas\n",
    "from brevitas.quant_tensor.int_quant_tensor import IntQuantTensor # Import Integer Quantization types for QNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a18705-e6c2-47dc-90f0-5a7b7cadcbce",
   "metadata": {},
   "source": [
    "## __Section II: Introduction of Basic Quantization Type in Brevitas__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3bbd81-86d0-471a-bc28-76500e55cbd4",
   "metadata": {},
   "source": [
    "#### __2.1 How to define Integer Quantization Type tensors in Brevitas__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca8af92-785e-4c34-858b-efdbd1193730",
   "metadata": {},
   "source": [
    "To train a low-precision QNN (1~8bit) for hardware accelerator design, *IntQuantTensor* is used for training and inferring the QNN models in *Brevitas*, which consists of six attitudes: \n",
    "\n",
    "<div style=\"width:fit-content; float:left; margin-right:20px;\">\n",
    "\n",
    "|Attitude      | Definiation                                |\n",
    "|--------------|--------------------------------------------|\n",
    "| *value*      | The non-quantized raw value                |\n",
    "| *scale*      | The scale rate to quantize the raw value   |\n",
    "| *zero_point* | The zero point to quantize the raw value   |\n",
    "| *bit_width*  | The bitwidth of the quantized value        |\n",
    "| *signed*     | Defining if the quantized value is signed  |\n",
    "| *training*   | Defining if this value is used in training |\n",
    "\n",
    "</div>\n",
    "<div style=\"clear:both;\"></div>\n",
    "\n",
    "Therefore, we can try to create the *IntQuantTensor* objects.\n",
    "\n",
    "First, we create three raw value tensors for our *IntQuantTensor* object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1350e65b-b2cf-47ef-bd6f-0b497c5f8fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Value for 1-d integer quantized tensor: \n",
      " tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]) \n",
      "\n",
      "Raw Value for 2-d integer quantized tensor: \n",
      " tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.]]) \n",
      "\n",
      "Raw Value for 3-d integer quantized tensor: \n",
      " tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11.],\n",
      "         [12., 13., 14., 15.]],\n",
      "\n",
      "        [[16., 17., 18., 19.],\n",
      "         [20., 21., 22., 23.],\n",
      "         [24., 25., 26., 27.],\n",
      "         [28., 29., 30., 31.]]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_1d = torch.arange(0, 10, dtype=torch.float32)\n",
    "value_2d = torch.arange(0, 16, dtype=torch.float32).reshape(4, 4)\n",
    "value_3d = torch.arange(0, 32, dtype=torch.float32).reshape(2, 4, 4)\n",
    "\n",
    "print(\"Raw Value for 1-d integer quantized tensor: \\n\", value_1d, \"\\n\")\n",
    "print(\"Raw Value for 2-d integer quantized tensor: \\n\", value_2d, \"\\n\")\n",
    "print(\"Raw Value for 3-d integer quantized tensor: \\n\", value_3d, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab70995-1f6a-48d3-a3e2-947d588d15d2",
   "metadata": {},
   "source": [
    "Then we can define the scale rate, zero point for three *IntQuantTensor* tensors. Their are fixed as 8 bit and unsigned data for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "190f7ef9-e422-48a9-948d-1b9a1a654bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_1d, scale_2d, scale_3d = 0.1, 0.2, 0.5\n",
    "zero_point_1d, zero_point_2d, zero_point_3d = 1.0, 2.0, 3.0\n",
    "bit_width = 8\n",
    "signed = False\n",
    "training = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba7c701-b069-4795-b159-c0b89435585a",
   "metadata": {},
   "source": [
    "Then, we can create three *IntQuantTensor* tensor as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52b157a1-c7a0-4019-9829-4dece435a396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-d integer quantized tensor: \n",
      " IntQuantTensor(value=tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]), scale=0.10000000149011612, zero_point=1.0, bit_width=8.0, signed_t=False, training_t=False) \n",
      "\n",
      "2-d integer quantized tensor: \n",
      " IntQuantTensor(value=tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.]]), scale=0.20000000298023224, zero_point=2.0, bit_width=8.0, signed_t=False, training_t=False) \n",
      "\n",
      "3-d integer quantized tensor: \n",
      " IntQuantTensor(value=tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11.],\n",
      "         [12., 13., 14., 15.]],\n",
      "\n",
      "        [[16., 17., 18., 19.],\n",
      "         [20., 21., 22., 23.],\n",
      "         [24., 25., 26., 27.],\n",
      "         [28., 29., 30., 31.]]]), scale=0.5, zero_point=3.0, bit_width=8.0, signed_t=False, training_t=False) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "int_tensor_1d = IntQuantTensor(value = value_1d, \n",
    "                               scale=scale_1d, \n",
    "                               zero_point=zero_point_1d, \n",
    "                               bit_width=bit_width, \n",
    "                               signed=signed, \n",
    "                               training=training)\n",
    "int_tensor_2d = IntQuantTensor(value = value_2d, \n",
    "                               scale=scale_2d, \n",
    "                               zero_point=zero_point_2d, \n",
    "                               bit_width=bit_width, \n",
    "                               signed=signed, \n",
    "                               training=training)\n",
    "int_tensor_3d = IntQuantTensor(value = value_3d, \n",
    "                               scale=scale_3d, \n",
    "                               zero_point=zero_point_3d, \n",
    "                               bit_width=bit_width, \n",
    "                               signed=signed, \n",
    "                               training=training)\n",
    "\n",
    "print(\"1-d integer quantized tensor: \\n\", int_tensor_1d, \"\\n\")\n",
    "print(\"2-d integer quantized tensor: \\n\", int_tensor_2d, \"\\n\")\n",
    "print(\"3-d integer quantized tensor: \\n\", int_tensor_3d, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5438247-c1e7-482d-885d-4aebaa8354d1",
   "metadata": {},
   "source": [
    "Tips: There is one interesting things in this *IntQuantTensor*. When we create this tensor, what we defined is *signed* and *training*. However, when we print this tensor, we can see the attitudes about sign and training is *signed_t* and *training_t*. Following is their different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfccf21c-fd66-4b10-966e-3a6b0a919739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "print(int_tensor_3d.signed)\n",
    "print(int_tensor_3d.signed_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126127b0-6d5e-4cdb-9692-7d881fad3032",
   "metadata": {},
   "source": [
    "Therefore, we can find that the data in *IntQuantTensor* is actually saved as floating-point, not the quantized integers. If we want to see the real integer value of these *IntQuantType* tensors, we can try the following two methods:\n",
    "\n",
    "1. Using the *int()* function of *IntQuantTensor*, which can output the quantized integer tensor based on the value, scale rate, and zero point.\n",
    "This function follows $Q_{out} = \\frac{Raw_{in}}{scale\\_rate} + zero\\_point$\n",
    "2. Manually extract the raw value, scale rate, and zero point to round the integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec12e2da-9f36-464f-ad3d-ad00977b5772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real quantized 1-d tensor: \n",
      " tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91], dtype=torch.uint8) \n",
      "\n",
      "Real quantized 2-d tensor: \n",
      " tensor([[ 2,  7, 12, 17],\n",
      "        [22, 27, 32, 37],\n",
      "        [42, 47, 52, 57],\n",
      "        [62, 67, 72, 77]], dtype=torch.uint8) \n",
      "\n",
      "Real quantized 3-d tensor: \n",
      " tensor([[[ 3,  5,  7,  9],\n",
      "         [11, 13, 15, 17],\n",
      "         [19, 21, 23, 25],\n",
      "         [27, 29, 31, 33]],\n",
      "\n",
      "        [[35, 37, 39, 41],\n",
      "         [43, 45, 47, 49],\n",
      "         [51, 53, 55, 57],\n",
      "         [59, 61, 63, 65]]], dtype=torch.uint8) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "real_int_tensor_1d = int_tensor_1d.int()\n",
    "real_int_tensor_2d = int_tensor_2d.int()\n",
    "real_int_tensor_3d = int_tensor_3d.int()\n",
    "\n",
    "print(\"Real quantized 1-d tensor: \\n\", real_int_tensor_1d, \"\\n\")\n",
    "print(\"Real quantized 2-d tensor: \\n\", real_int_tensor_2d, \"\\n\")\n",
    "print(\"Real quantized 3-d tensor: \\n\", real_int_tensor_3d, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da93274d-5b65-4df6-97e8-6e9a74665f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real quantized 1-d tensor: \n",
      " tensor([ 1., 11., 21., 31., 41., 51., 61., 71., 81., 91.]) \n",
      "\n",
      "Real quantized 2-d tensor: \n",
      " tensor([[ 2.,  7., 12., 17.],\n",
      "        [22., 27., 32., 37.],\n",
      "        [42., 47., 52., 57.],\n",
      "        [62., 67., 72., 77.]]) \n",
      "\n",
      "Real quantized 3-d tensor: \n",
      " tensor([[[ 3.,  5.,  7.,  9.],\n",
      "         [11., 13., 15., 17.],\n",
      "         [19., 21., 23., 25.],\n",
      "         [27., 29., 31., 33.]],\n",
      "\n",
      "        [[35., 37., 39., 41.],\n",
      "         [43., 45., 47., 49.],\n",
      "         [51., 53., 55., 57.],\n",
      "         [59., 61., 63., 65.]]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "real_int_tensor_1d = int_tensor_1d.int(float_datatype=True)\n",
    "real_int_tensor_2d = int_tensor_2d.int(float_datatype=True)\n",
    "real_int_tensor_3d = int_tensor_3d.int(float_datatype=True)\n",
    "\n",
    "print(\"Real quantized 1-d tensor: \\n\", real_int_tensor_1d, \"\\n\")\n",
    "print(\"Real quantized 2-d tensor: \\n\", real_int_tensor_2d, \"\\n\")\n",
    "print(\"Real quantized 3-d tensor: \\n\", real_int_tensor_3d, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee07df6d-02f3-4b77-980a-76758bbfbbae",
   "metadata": {},
   "source": [
    "We can notice that the *int()* function needs a *float_datatype=True* to convert the quantized data to a floating-point format. Otherwise, it cannot be used in network training and inference. \n",
    "\n",
    "Another method is manually extracting the raw value, scale rate, and zero point, computing the result following the equation above, and rounding the output as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa784c4c-a8df-4213-9ec8-63449c23e7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually quantized 1-d tensor: \n",
      " tensor([ 1., 11., 21., 31., 41., 51., 61., 71., 81., 91.]) \n",
      "\n",
      "Manually quantized 2-d tensor: \n",
      " tensor([[ 2.,  7., 12., 17.],\n",
      "        [22., 27., 32., 37.],\n",
      "        [42., 47., 52., 57.],\n",
      "        [62., 67., 72., 77.]]) \n",
      "\n",
      "Manually quantized 3-d tensor: \n",
      " tensor([[[ 3.,  5.,  7.,  9.],\n",
      "         [11., 13., 15., 17.],\n",
      "         [19., 21., 23., 25.],\n",
      "         [27., 29., 31., 33.]],\n",
      "\n",
      "        [[35., 37., 39., 41.],\n",
      "         [43., 45., 47., 49.],\n",
      "         [51., 53., 55., 57.],\n",
      "         [59., 61., 63., 65.]]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "extract_scale_1d, extract_scale_2d, extract_scale_3d = int_tensor_1d.scale, int_tensor_2d.scale, int_tensor_3d.scale\n",
    "extract_zero_point_1d, extract_zero_point_2d, extract_zero_point_3d = int_tensor_1d.zero_point, int_tensor_2d.zero_point, int_tensor_3d.zero_point\n",
    "\n",
    "manual_int_tensor_1d = torch.round((int_tensor_1d.value / int_tensor_1d.scale) + int_tensor_1d.zero_point)\n",
    "manual_int_tensor_2d = torch.round((int_tensor_2d.value / int_tensor_2d.scale) + int_tensor_2d.zero_point)\n",
    "manual_int_tensor_3d = torch.round((int_tensor_3d.value / int_tensor_3d.scale) + int_tensor_3d.zero_point)\n",
    "\n",
    "print(\"Manually quantized 1-d tensor: \\n\", real_int_tensor_1d, \"\\n\")\n",
    "print(\"Manually quantized 2-d tensor: \\n\", real_int_tensor_2d, \"\\n\")\n",
    "print(\"Manually quantized 3-d tensor: \\n\", real_int_tensor_3d, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae97dce-6d6c-4665-8080-7c6d1eaa173f",
   "metadata": {},
   "source": [
    "Actually, we don't need to extract the scale rate and zero point, *IntQuantTensor* offers one function *_pre_round_int_value* to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3123776a-367e-4fd7-aa31-131a32c5c68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually quantized 1-d tensor: \n",
      " tensor([ 1., 11., 21., 31., 41., 51., 61., 71., 81., 91.]) \n",
      "\n",
      "Manually quantized 2-d tensor: \n",
      " tensor([[ 2.,  7., 12., 17.],\n",
      "        [22., 27., 32., 37.],\n",
      "        [42., 47., 52., 57.],\n",
      "        [62., 67., 72., 77.]]) \n",
      "\n",
      "Manually quantized 3-d tensor: \n",
      " tensor([[[ 3.,  5.,  7.,  9.],\n",
      "         [11., 13., 15., 17.],\n",
      "         [19., 21., 23., 25.],\n",
      "         [27., 29., 31., 33.]],\n",
      "\n",
      "        [[35., 37., 39., 41.],\n",
      "         [43., 45., 47., 49.],\n",
      "         [51., 53., 55., 57.],\n",
      "         [59., 61., 63., 65.]]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "manual_int_tensor_1d = torch.round(int_tensor_1d._pre_round_int_value)\n",
    "manual_int_tensor_2d = torch.round(int_tensor_2d._pre_round_int_value)\n",
    "manual_int_tensor_3d = torch.round(int_tensor_3d._pre_round_int_value)\n",
    "\n",
    "print(\"Manually quantized 1-d tensor: \\n\", real_int_tensor_1d, \"\\n\")\n",
    "print(\"Manually quantized 2-d tensor: \\n\", real_int_tensor_2d, \"\\n\")\n",
    "print(\"Manually quantized 3-d tensor: \\n\", real_int_tensor_3d, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5084aa-369d-4814-acfe-c3a41e53cf30",
   "metadata": {},
   "source": [
    "Here, we are using the regular *torch.round* to round the results with floating-point format to integers. However, Brevitas also offered one *round_ste* function specifically designed for the training of QNN. If you are using manual rounding in your training code, you can consider using *round_ste*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dce1f5d9-c313-4675-9b9f-3146691115f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round_ste quantized 1-d tensor: \n",
      " tensor([ 1., 11., 21., 31., 41., 51., 61., 71., 81., 91.]) \n",
      "\n",
      "round_ste quantized 2-d tensor: \n",
      " tensor([[ 2.,  7., 12., 17.],\n",
      "        [22., 27., 32., 37.],\n",
      "        [42., 47., 52., 57.],\n",
      "        [62., 67., 72., 77.]]) \n",
      "\n",
      "round_ste quantized 3-d tensor: \n",
      " tensor([[[ 3.,  5.,  7.,  9.],\n",
      "         [11., 13., 15., 17.],\n",
      "         [19., 21., 23., 25.],\n",
      "         [27., 29., 31., 33.]],\n",
      "\n",
      "        [[35., 37., 39., 41.],\n",
      "         [43., 45., 47., 49.],\n",
      "         [51., 53., 55., 57.],\n",
      "         [59., 61., 63., 65.]]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from brevitas.function.ops_ste import round_ste\n",
    "\n",
    "round_ste_int_tensor_1d = round_ste(int_tensor_1d._pre_round_int_value)\n",
    "round_ste_int_tensor_2d = round_ste(int_tensor_2d._pre_round_int_value)\n",
    "round_ste_int_tensor_3d = round_ste(int_tensor_3d._pre_round_int_value)\n",
    "\n",
    "print(\"round_ste quantized 1-d tensor: \\n\", real_int_tensor_1d, \"\\n\")\n",
    "print(\"round_ste quantized 2-d tensor: \\n\", real_int_tensor_2d, \"\\n\")\n",
    "print(\"round_ste quantized 3-d tensor: \\n\", real_int_tensor_3d, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f894cf08-74da-46c5-8a38-5bc3bf7a67c3",
   "metadata": {},
   "source": [
    "#### __2.2 What will Happen When the Quantized Data is Out of the Range of the Bit Width__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ed0907-4be1-4f4d-ae47-8168a416e502",
   "metadata": {},
   "source": [
    "We define a 1-d raw tensor with a small scale rate and small bit width to test what will happen when the quantized output is out of the range of bit width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fcff3eb-530d-45cd-9349-540292ea4c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oringinal quantized 1-d tensor: \n",
      " IntQuantTensor(value=tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]), scale=0.10000000149011612, zero_point=1.0, bit_width=4.0, signed_t=False, training_t=False) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_1d = torch.arange(0, 10, dtype=torch.float32)\n",
    "scale_1d = 0.1\n",
    "zero_point_1d = 1\n",
    "bit_width = 4\n",
    "signed = False\n",
    "\n",
    "new_quant_tensor = IntQuantTensor(value = value_1d, \n",
    "                                  scale=scale_1d, \n",
    "                                  zero_point=zero_point_1d, \n",
    "                                  bit_width=bit_width, \n",
    "                                  signed=signed, \n",
    "                                  training=False)\n",
    "\n",
    "print(\"Oringinal quantized 1-d tensor: \\n\", new_quant_tensor, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c36384a-3a66-4780-ac84-b8e521760b5e",
   "metadata": {},
   "source": [
    "If we use the *int()* function of *IntQuantTensor*, there will be an error to show that *IntQuantTensor not valid.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25ea01de-13bf-41e5-ba15-1f97ede3a6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is an ERROR: IntQuantTensor not valid.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"Rounded quantized 1-d tensor with int(): \\n\", new_quant_tensor.int(float_datatype=True), \"\\n\")\n",
    "except Exception as e:\n",
    "    print(\"There is an ERROR:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9fd7b5-2f7a-4bf1-b95f-8aefb6010589",
   "metadata": {},
   "source": [
    "But for the manually quantization, the error will not happen, but the output will also out of the range of 4-bit unsigned quantization (0~15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06464708-e815-4dcc-9778-0070ec1c8b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manully rounded quantized 1-d tensor with torch.int: \n",
      " tensor([ 1., 11., 21., 31., 41., 51., 61., 71., 81., 91.]) \n",
      "\n",
      "Manully rounded quantized 1-d tensor with round_ste: \n",
      " tensor([ 1., 11., 21., 31., 41., 51., 61., 71., 81., 91.]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "manual_round_int_tensor_1d = torch.round(new_quant_tensor._pre_round_int_value)\n",
    "manual_round_ste_int_tensor_1d = round_ste(new_quant_tensor._pre_round_int_value)\n",
    "\n",
    "print(\"Manully rounded quantized 1-d tensor with torch.int: \\n\", manual_round_int_tensor_1d, \"\\n\")\n",
    "print(\"Manully rounded quantized 1-d tensor with round_ste: \\n\", manual_round_ste_int_tensor_1d, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edcdada-f864-45c2-9d61-34779247882f",
   "metadata": {},
   "source": [
    "Therefore, we need to use the manully quantization applying a limitation for these quantized tensor if we want to show the quantized data anyway:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9c9ceae-a1bc-4603-8c26-c2fe2e1a6eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limited rounded quantized 1-d tensor with torch.int: \n",
      " tensor([ 1., 11., 15., 15., 15., 15., 15., 15., 15., 15.]) \n",
      "\n",
      "Limited rounded quantized 1-d tensor with round_ste: \n",
      " tensor([ 1., 11., 15., 15., 15., 15., 15., 15., 15., 15.]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "limited_round_int_tensor_1d = torch.where(manual_round_int_tensor_1d >= ((2**new_quant_tensor.bit_width) - 1), \n",
    "                                          torch.full_like(manual_round_int_tensor_1d, ((2**new_quant_tensor.bit_width) - 1)), \n",
    "                                          manual_round_int_tensor_1d)\n",
    "limited_round_ste_int_tensor_1d = torch.where(manual_round_ste_int_tensor_1d >= ((2**new_quant_tensor.bit_width) - 1), \n",
    "                                          torch.full_like(manual_round_ste_int_tensor_1d, ((2**new_quant_tensor.bit_width) - 1)), \n",
    "                                          manual_round_ste_int_tensor_1d)\n",
    "\n",
    "print(\"Limited rounded quantized 1-d tensor with torch.int: \\n\", limited_round_int_tensor_1d, \"\\n\")\n",
    "print(\"Limited rounded quantized 1-d tensor with round_ste: \\n\", limited_round_ste_int_tensor_1d, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0498f493-8c2a-44d8-9274-708e6e0e8612",
   "metadata": {},
   "source": [
    "For the signed quantzation, the scripts are similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8439bb4b-eda5-4c20-850e-7fa9eee308ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oringinal signed quantized 1-d tensor: \n",
      " IntQuantTensor(value=tensor([-0., -1., -2., -3., -4., -5., -6., -7., -8., -9.]), scale=0.10000000149011612, zero_point=15.0, bit_width=4.0, signed_t=True, training_t=False) \n",
      "\n",
      "Manully rounded quantized 1-d tensor with torch.int: \n",
      " tensor([ 15.,   5.,  -5., -15., -25., -35., -45., -55., -65., -75.]) \n",
      "\n",
      "Manully rounded quantized 1-d tensor with round_ste: \n",
      " tensor([ 15.,   5.,  -5., -15., -25., -35., -45., -55., -65., -75.]) \n",
      "\n",
      "Limited rounded quantized 1-d tensor with torch.int: \n",
      " tensor([ 7.,  5., -5., -8., -8., -8., -8., -8., -8., -8.]) \n",
      "\n",
      "Limited rounded quantized 1-d tensor with round_ste: \n",
      " tensor([ 7.,  5., -5., -8., -8., -8., -8., -8., -8., -8.]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_1d = -1.0 * torch.arange(0, 10, dtype=torch.float32)\n",
    "scale_1d = 0.1\n",
    "zero_point_1d = 15\n",
    "bit_width = 4\n",
    "signed = True\n",
    "\n",
    "new_quant_tensor = IntQuantTensor(value = value_1d, \n",
    "                                  scale=scale_1d, \n",
    "                                  zero_point=zero_point_1d, \n",
    "                                  bit_width=bit_width, \n",
    "                                  signed=signed, \n",
    "                                  training=False)\n",
    "\n",
    "print(\"Oringinal signed quantized 1-d tensor: \\n\", new_quant_tensor, \"\\n\")\n",
    "\n",
    "manual_round_int_tensor_1d = torch.round(new_quant_tensor._pre_round_int_value)\n",
    "manual_round_ste_int_tensor_1d = round_ste(new_quant_tensor._pre_round_int_value)\n",
    "\n",
    "print(\"Manully rounded quantized 1-d tensor with torch.int: \\n\", manual_round_int_tensor_1d, \"\\n\")\n",
    "print(\"Manully rounded quantized 1-d tensor with round_ste: \\n\", manual_round_ste_int_tensor_1d, \"\\n\")\n",
    "\n",
    "limited_round_int_tensor_1d = torch.where(manual_round_int_tensor_1d >= ((2**(new_quant_tensor.bit_width-1)) - 1), \n",
    "                                          torch.full_like(manual_round_int_tensor_1d, ((2**(new_quant_tensor.bit_width-1)) - 1)), \n",
    "                                          torch.where(manual_round_int_tensor_1d <= (-1.0*(2**(new_quant_tensor.bit_width-1))), \n",
    "                                                torch.full_like(manual_round_int_tensor_1d, (-1.0*(2**(new_quant_tensor.bit_width-1)))), \n",
    "                                                manual_round_int_tensor_1d))\n",
    "limited_round_ste_int_tensor_1d = torch.where(manual_round_ste_int_tensor_1d >= ((2**(new_quant_tensor.bit_width-1)) - 1), \n",
    "                                          torch.full_like(manual_round_ste_int_tensor_1d, ((2**(new_quant_tensor.bit_width-1)) - 1)), \n",
    "                                          torch.where(manual_round_ste_int_tensor_1d <= (-1.0*(2**(new_quant_tensor.bit_width-1))), \n",
    "                                                torch.full_like(manual_round_ste_int_tensor_1d, (-1.0*(2**(new_quant_tensor.bit_width-1)))), \n",
    "                                                manual_round_ste_int_tensor_1d))\n",
    "\n",
    "print(\"Limited rounded quantized 1-d tensor with torch.int: \\n\", limited_round_int_tensor_1d, \"\\n\")\n",
    "print(\"Limited rounded quantized 1-d tensor with round_ste: \\n\", limited_round_ste_int_tensor_1d, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f309e905-95c6-4c69-ba20-5368ccce82d4",
   "metadata": {},
   "source": [
    "Therefore, we can create one function to do these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e10e9fe4-ce4f-49b1-8e4a-ac722b357a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quant_tensor(raw_in, quant_type = False):\n",
    "    if (raw_in.training):\n",
    "        manual_round_int_tensor = round_ste(raw_in._pre_round_int_value)\n",
    "        if (raw_in.signed):\n",
    "            limited_round_int_tensor = torch.where(manual_round_int_tensor >= ((2**(raw_in.bit_width-1)) - 1), \n",
    "                                                   torch.full_like(manual_round_int_tensor, ((2**(raw_in.bit_width-1)) - 1)), \n",
    "                                                   torch.where(manual_round_int_tensor <= (-1.0*(2**(raw_in.bit_width-1))), \n",
    "                                                               torch.full_like(manual_round_int_tensor, (-1.0*(2**(raw_in.bit_width-1)))), \n",
    "                                                               manual_round_int_tensor))\n",
    "        else:\n",
    "            limited_round_int_tensor = torch.where(manual_round_int_tensor >= ((2**raw_in.bit_width) - 1), \n",
    "                                                   torch.full_like(manual_round_int_tensor, ((2**raw_in.bit_width) - 1)), \n",
    "                                                   manual_round_int_tensor)\n",
    "    else:\n",
    "        manual_round_int_tensor = torch.round(raw_in._pre_round_int_value)\n",
    "        if (raw_in.signed):\n",
    "            limited_round_int_tensor = torch.where(manual_round_int_tensor >= ((2**(raw_in.bit_width-1)) - 1), \n",
    "                                                   torch.full_like(manual_round_int_tensor, ((2**(raw_in.bit_width-1)) - 1)), \n",
    "                                                   torch.where(manual_round_int_tensor <= (-1.0*(2**(raw_in.bit_width-1))), \n",
    "                                                               torch.full_like(manual_round_int_tensor, (-1.0*(2**(raw_in.bit_width-1)))), \n",
    "                                                               manual_round_int_tensor))\n",
    "        else:\n",
    "            limited_round_int_tensor = torch.where(manual_round_int_tensor >= ((2**raw_in.bit_width) - 1), \n",
    "                                                   torch.full_like(manual_round_int_tensor, ((2**raw_in.bit_width) - 1)), \n",
    "                                                   manual_round_int_tensor)\n",
    "\n",
    "    if (quant_type):\n",
    "        return IntQuantTensor(value = limited_round_int_tensor, \n",
    "                              scale=1.0, \n",
    "                              zero_point=0.0, \n",
    "                              bit_width=raw_in.bit_width, \n",
    "                              signed=raw_in.signed, \n",
    "                              training=raw_in.training)\n",
    "    else:\n",
    "        return limited_round_int_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6360fc5-4bdd-40d5-9706-046586ec8aeb",
   "metadata": {},
   "source": [
    "Following is the test of this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "044a7785-2a27-442e-a3aa-ef1aae0739f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw 1-d integer quantized tensor for test: \n",
      " IntQuantTensor(value=tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]), scale=0.5, zero_point=1.5, bit_width=4.0, signed_t=False, training_t=False) \n",
      "\n",
      "Raw 2-d integer quantized tensor for test: \n",
      " IntQuantTensor(value=tensor([[ -0.,  -1.,  -2.,  -3.],\n",
      "        [ -4.,  -5.,  -6.,  -7.],\n",
      "        [ -8.,  -9., -10., -11.],\n",
      "        [-12., -13., -14., -15.]]), scale=0.20000000298023224, zero_point=2.5, bit_width=4.0, signed_t=True, training_t=False) \n",
      "\n",
      "Raw 3-d integer quantized tensor for test: \n",
      " IntQuantTensor(value=tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11.],\n",
      "         [12., 13., 14., 15.]],\n",
      "\n",
      "        [[16., 17., 18., 19.],\n",
      "         [20., 21., 22., 23.],\n",
      "         [24., 25., 26., 27.],\n",
      "         [28., 29., 30., 31.]]]), scale=0.10000000149011612, zero_point=3.5, bit_width=4.0, signed_t=False, training_t=False) \n",
      " \n",
      "\n",
      "Rounded 1-d integer quantized tensor result: \n",
      " IntQuantTensor(value=tensor([ 2.,  4.,  6.,  8., 10., 12., 14., 15., 15., 15.]), scale=1.0, zero_point=0.0, bit_width=4.0, signed_t=False, training_t=False) \n",
      "\n",
      "Rounded 2-d integer quantized tensor result: \n",
      " tensor([[ 2., -2., -8., -8.],\n",
      "        [-8., -8., -8., -8.],\n",
      "        [-8., -8., -8., -8.],\n",
      "        [-8., -8., -8., -8.]]) \n",
      "\n",
      "Rounded 3-d integer quantized tensor result: \n",
      " tensor([[[ 4., 14., 15., 15.],\n",
      "         [15., 15., 15., 15.],\n",
      "         [15., 15., 15., 15.],\n",
      "         [15., 15., 15., 15.]],\n",
      "\n",
      "        [[15., 15., 15., 15.],\n",
      "         [15., 15., 15., 15.],\n",
      "         [15., 15., 15., 15.],\n",
      "         [15., 15., 15., 15.]]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_1d = torch.arange(0, 10, dtype=torch.float32)\n",
    "value_2d = -1.0 * torch.arange(0, 16, dtype=torch.float32).reshape(4, 4)\n",
    "value_3d = torch.arange(0, 32, dtype=torch.float32).reshape(2, 4, 4)\n",
    "\n",
    "scale_1d, scale_2d, scale_3d = 0.5, 0.2, 0.1\n",
    "zero_point_1d, zero_point_2d, zero_point_3d = 1.5, 2.5, 3.5\n",
    "bit_width = 4\n",
    "signed_1d, signed_2d, signed_3d = False, True, False\n",
    "training = False\n",
    "\n",
    "test_int_tensor_1d = IntQuantTensor(value = value_1d, \n",
    "                                    scale=scale_1d, \n",
    "                                    zero_point=zero_point_1d, \n",
    "                                    bit_width=bit_width, \n",
    "                                    signed=signed_1d, \n",
    "                                    training=training)\n",
    "test_int_tensor_2d = IntQuantTensor(value = value_2d, \n",
    "                                    scale=scale_2d, \n",
    "                                    zero_point=zero_point_2d, \n",
    "                                    bit_width=bit_width, \n",
    "                                    signed=signed_2d, \n",
    "                                    training=training)\n",
    "test_int_tensor_3d = IntQuantTensor(value = value_3d, \n",
    "                                    scale=scale_3d, \n",
    "                                    zero_point=zero_point_3d, \n",
    "                                    bit_width=bit_width, \n",
    "                                    signed=signed_3d, \n",
    "                                    training=training)\n",
    "\n",
    "print(\"Raw 1-d integer quantized tensor for test: \\n\", test_int_tensor_1d, \"\\n\")\n",
    "print(\"Raw 2-d integer quantized tensor for test: \\n\", test_int_tensor_2d, \"\\n\")\n",
    "print(\"Raw 3-d integer quantized tensor for test: \\n\", test_int_tensor_3d, \"\\n \\n\")\n",
    "\n",
    "quantized_int_tensor_1d = quant_tensor(test_int_tensor_1d, quant_type=True)\n",
    "quantized_int_tensor_2d = quant_tensor(test_int_tensor_2d)\n",
    "quantized_int_tensor_3d = quant_tensor(test_int_tensor_3d)\n",
    "\n",
    "print(\"Rounded 1-d integer quantized tensor result: \\n\", quantized_int_tensor_1d, \"\\n\")\n",
    "print(\"Rounded 2-d integer quantized tensor result: \\n\", quantized_int_tensor_2d, \"\\n\")\n",
    "print(\"Rounded 3-d integer quantized tensor result: \\n\", quantized_int_tensor_3d, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858bf264-37b0-49a3-a3d9-76db0ba872a3",
   "metadata": {},
   "source": [
    "## __Section III: Computation of Quantized Tensor in Brevitas__\n",
    "#### __3.1 Addition of Quantized Tensor in Brevitas__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a008c39-0627-4ba8-8346-5bc8c7f2abee",
   "metadata": {},
   "source": [
    "Considering the quantized tensors in Brevitas have additional attitudes of scale rate, zero point, and bit width. Their computation is more complex than regular tensors. Here we define two *IntQuantTensor* with completely different scale rate, zero point, and bit width to execute the addition. There will be an ERROR of *\"Scaling factors are different\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8de8d3f4-9971-4016-be70-ea5974b02426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught a RuntimeError: Scaling factors are different\n"
     ]
    }
   ],
   "source": [
    "value_1 = torch.arange(1, 5, dtype=torch.float32)\n",
    "value_2 = torch.arange(2, 6, dtype=torch.float32)\n",
    "\n",
    "scale_1, scale_2 = 0.2, 0.5\n",
    "zero_point_1, zero_point_2 = 2.5, 3.5\n",
    "bit_width_1, bit_width_2 = 6, 8\n",
    "signed = False\n",
    "training = False\n",
    "\n",
    "int_tensor_1 = IntQuantTensor(value=value_1, \n",
    "                              scale=scale_1, \n",
    "                              zero_point=zero_point_1, \n",
    "                              bit_width=bit_width_1, \n",
    "                              signed=signed, \n",
    "                              training=training)\n",
    "int_tensor_2 = IntQuantTensor(value=value_2, \n",
    "                              scale=scale_2, \n",
    "                              zero_point=zero_point_2, \n",
    "                              bit_width=bit_width_2, \n",
    "                              signed=signed, \n",
    "                              training=training)\n",
    "try:\n",
    "    int_tensor_result = int_tensor_1 + int_tensor_2\n",
    "except RuntimeError as e:\n",
    "    print(f\"Caught a RuntimeError: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b631092f-9141-4f55-a049-ae4c9b9238d3",
   "metadata": {},
   "source": [
    "Therefore, we can define a function to change the scale rate when it's necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244e5c05-3f8c-4a63-8b8d-d6c34ec74fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quant_transform(tensor_in, new_scale):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff83e110-3434-4f4b-a8e3-076818a0fd64",
   "metadata": {},
   "source": [
    "If we unify the scale rate with different zero points and bit widths of these two tensors, the ERROR has gone.\n",
    "\n",
    "However, the interesting thing is that if we directly add two quantized tensors together and convert them to an integer format, comparing with converting two input tensors as integers first and computing their sum second, these two results are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0223efe2-fb81-4cfd-a9cb-b2c7e7685dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Input Tensor 1: \n",
      " IntQuantTensor(value=tensor([1., 2., 3., 4.]), scale=0.20000000298023224, zero_point=2.5, bit_width=6.0, signed_t=False, training_t=False) \n",
      "\n",
      "Raw Input Tensor 2: \n",
      " IntQuantTensor(value=tensor([2., 3., 4., 5.]), scale=0.20000000298023224, zero_point=3.5, bit_width=8.0, signed_t=False, training_t=False) \n",
      "\n",
      "Raw Addition Result: \n",
      " IntQuantTensor(value=tensor([3., 5., 7., 9.]), scale=0.20000000298023224, zero_point=6.0, bit_width=9.0, signed_t=False, training_t=False) \n",
      "\n",
      "Quantized Input Tensor 1: \n",
      " tensor([ 8., 12., 18., 22.]) \n",
      "\n",
      "Quantized Input Tensor 2: \n",
      " tensor([14., 18., 24., 28.]) \n",
      "\n",
      "New Addition Result: \n",
      " tensor([22., 30., 42., 50.]) \n",
      "\n",
      "Quantized Previous Addition Result: \n",
      " tensor([21., 31., 41., 51.]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_1 = torch.arange(1, 5, dtype=torch.float32)\n",
    "value_2 = torch.arange(2, 6, dtype=torch.float32)\n",
    "\n",
    "scale = 0.2\n",
    "zero_point_1, zero_point_2 = 2.5, 3.5\n",
    "bit_width_1, bit_width_2 = 6, 8\n",
    "signed = False\n",
    "training = False\n",
    "\n",
    "int_tensor_1 = IntQuantTensor(value=value_1, \n",
    "                              scale=scale, \n",
    "                              zero_point=zero_point_1, \n",
    "                              bit_width=bit_width_1, \n",
    "                              signed=signed, \n",
    "                              training=training)\n",
    "int_tensor_2 = IntQuantTensor(value=value_2, \n",
    "                              scale=scale, \n",
    "                              zero_point=zero_point_2, \n",
    "                              bit_width=bit_width_2, \n",
    "                              signed=signed, \n",
    "                              training=training)\n",
    "\n",
    "int_tensor_result = int_tensor_1 + int_tensor_2\n",
    "    \n",
    "print(\"Raw Input Tensor 1: \\n\", int_tensor_1, \"\\n\")\n",
    "print(\"Raw Input Tensor 2: \\n\", int_tensor_2, \"\\n\")\n",
    "print(\"Raw Addition Result: \\n\", int_tensor_result, \"\\n\")\n",
    "\n",
    "rounded_int_tensor_1 = quant_tensor(int_tensor_1)\n",
    "rounded_int_tensor_2 = quant_tensor(int_tensor_2)\n",
    "rounded_int_tensor_result = rounded_int_tensor_1+rounded_int_tensor_2\n",
    "rounded_old_int_tensor_result = quant_tensor(int_tensor_result)\n",
    "\n",
    "print(\"Quantized Input Tensor 1: \\n\", rounded_int_tensor_1, \"\\n\")\n",
    "print(\"Quantized Input Tensor 2: \\n\", rounded_int_tensor_2, \"\\n\")\n",
    "print(\"New Addition Result: \\n\", rounded_int_tensor_result, \"\\n\")\n",
    "print(\"Quantized Previous Addition Result: \\n\", rounded_old_int_tensor_result, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344ef9f6-1ba6-4940-970f-c3b733847c78",
   "metadata": {},
   "source": [
    "However, if we compute the integer format of two input *IntQuantTensor*s without the rounding, then add them together and round the result, we can find that the result is the same as the rounded integer value for the result of directly adding the input *IntQuantTensor*s. It means that the addition of *IntQuantTensor* is not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19ad7bfd-4553-4043-9b63-c8fc5534cb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized Input Tensor 1 without Rounding: \n",
      " tensor([ 7.5000, 12.5000, 17.5000, 22.5000]) \n",
      "\n",
      "Quantized Input Tensor 2 without Rounding: \n",
      " tensor([13.5000, 18.5000, 23.5000, 28.5000]) \n",
      "\n",
      "Addition Result without Rounding: \n",
      " tensor([21., 31., 41., 51.]) \n",
      "\n",
      "Rounded Quantized Addition Result: \n",
      " tensor([21., 31., 41., 51.]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "unround_int_tensor_1 = int_tensor_1.value / int_tensor_1.scale + int_tensor_1.zero_point\n",
    "unround_int_tensor_2 = int_tensor_2.value / int_tensor_2.scale + int_tensor_2.zero_point\n",
    "unround_int_tensor_sum = unround_int_tensor_1 + unround_int_tensor_2\n",
    "simulated_int_tensor_sum = torch.round(unround_int_tensor_sum)\n",
    "\n",
    "print(\"Quantized Input Tensor 1 without Rounding: \\n\", unround_int_tensor_1, \"\\n\")\n",
    "print(\"Quantized Input Tensor 2 without Rounding: \\n\", unround_int_tensor_2, \"\\n\")\n",
    "print(\"Addition Result without Rounding: \\n\", unround_int_tensor_sum, \"\\n\")\n",
    "print(\"Rounded Quantized Addition Result: \\n\", simulated_int_tensor_sum, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cc94b8-2f9f-46e5-a152-e807529a2b37",
   "metadata": {},
   "source": [
    "This means that Brevitas has not really compute the *IntQuantTensor* as integers. To accurately simulate the integer addition of *IntQuantTensor*, we can create a function as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5aa9e85e-0265-4b80-8784-700d22fbc2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quant_add(tensor_in_0, tensor_in_1, quant_type = False):\n",
    "    unround_tensor_in_0 = quant_tensor(tensor_in_0)\n",
    "    unround_tensor_in_1 = quant_tensor(tensor_in_1)\n",
    "    \n",
    "    new_bit_width = max(tensor_in_0.bit_width, tensor_in_1.bit_width) + 1\n",
    "    new_signed = tensor_in_0.signed | tensor_in_1.signed\n",
    "    new_training = tensor_in_0.training | tensor_in_1.training\n",
    "    \n",
    "    int_tensor_sum = unround_tensor_in_0+unround_tensor_in_1\n",
    "\n",
    "    if (new_signed):\n",
    "        limited_int_tensor_sum = torch.where(int_tensor_sum >= ((2**(new_bit_width-1)) - 1), \n",
    "                                             torch.full_like(int_tensor_sum, ((2**(new_bit_width-1)) - 1)), \n",
    "                                             torch.where(int_tensor_sum <= (-1.0*(2**(new_bit_width-1))), \n",
    "                                                         torch.full_like(int_tensor_sum, (-1.0*(2**(new_bit_width-1)))), \n",
    "                                                         int_tensor_sum))\n",
    "    else:\n",
    "        limited_int_tensor_sum = torch.where(int_tensor_sum >= ((2**new_bit_width) - 1), \n",
    "                                             torch.full_like(int_tensor_sum, ((2**new_bit_width) - 1)), \n",
    "                                                             int_tensor_sum)\n",
    "    \n",
    "\n",
    "    if (quant_type):\n",
    "        \n",
    "        return IntQuantTensor(value = limited_int_tensor_sum, \n",
    "                              scale=1.0, \n",
    "                              zero_point=0.0, \n",
    "                              bit_width=new_bit_width, \n",
    "                              signed=new_signed, \n",
    "                              training=new_training)\n",
    "    else:\n",
    "        return limited_int_tensor_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "950ae4bd-b506-4fa7-be11-a6ed93c7c5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IntQuantTensor(value=tensor([22., 30., 42., 50.]), scale=1.0, zero_point=0.0, bit_width=9.0, signed_t=False, training_t=False)\n"
     ]
    }
   ],
   "source": [
    "print(quant_add(int_tensor_1, int_tensor_2, quant_type=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f737e9-acc8-44c8-8cbe-4436c2f820dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
